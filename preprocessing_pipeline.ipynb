{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data\n",
    "---\n",
    "Complete the following:\n",
    "- Use the parameter 'usecols' to select all columns from the raw data that are needed\n",
    "- Use the parameter 'parse_dates' to have Pandas automatically parse date info as it is brought in\n",
    "- Use the paremeter 'index_col' to set the index to the datetime column if this is time series data\n",
    "- Use the .query() function to import data that's conditional upon another columns values\n",
    "- Anonymize or remove sensitive data\n",
    "- Remove unneeded columns such as timestamps, counts, etc. that are guaranteed to have no relationship on the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonathan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (50,172,255,256,257,258,268,280,376) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully imported.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonathan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (50,255,256,257,258,260,268) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data successfully imported.\n",
      "Data Shape: (20000, 379)\n",
      "Test Shape: (20000, 379)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns # Used for correlation heat map\n",
    "from sklearn.datasets import make_classification\n",
    "from skorch import NeuralNetClassifier, NeuralNetRegressor\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "raw_data = pd.read_csv('./data/TrainingSet.csv')\n",
    "if isinstance(raw_data, pd.DataFrame):\n",
    "    print(\"Data successfully imported.\")\n",
    "else:\n",
    "    print(\"Data failed to import.\")\n",
    "\n",
    "\n",
    "test_set = pd.read_csv('./data/TestSet.csv')\n",
    "if isinstance(test_set, pd.DataFrame):\n",
    "    print(\"Test data successfully imported.\")\n",
    "else:\n",
    "    print(\"Test data failed to import.\")\n",
    "    \n",
    "# Remove unneeded columns\n",
    "del raw_data['timestamp']\n",
    "del test_set['timestamp']\n",
    "\n",
    "# Time series example\n",
    "# hourly_weather_data = pd.read_csv('./data/raw_weather_data.csv', usecols=['DATE','REPORT_TYPE','HourlyDryBulbTemperature', 'HourlyPrecipitation'] , parse_dates=[\"DATE\"], index_col=\"DATE\").query(\"REPORT_TYPE == 'FM-15'\")\n",
    "\n",
    "print(\"Data Shape:\",raw_data.shape) \n",
    "print(\"Test Shape:\",test_set.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Data into Training, Validation, Test, and Target Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape: (16000, 378)\n",
      "Validation Set Shape: (4000, 378)\n",
      "Test Set Shape: (20000, 378)\n",
      "11605    2840.739854\n",
      "14073    3060.220662\n",
      "526      2871.751466\n",
      "16969    2696.647037\n",
      "14771    2474.468696\n",
      "Name: job_performance, dtype: float64\n",
      "18818    2447.550539\n",
      "16329    2603.743230\n",
      "9684     3008.842835\n",
      "6938     2570.544318\n",
      "8714     3312.652231\n",
      "Name: job_performance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate data into training, validation, and test sets\n",
    "train_set, validation_set, train_targets, validation_targets = train_test_split(raw_data, raw_data['job_performance'], test_size=0.2)\n",
    "\n",
    "# Set target and drop from training/test set data\n",
    "del train_set['job_performance']\n",
    "del validation_set['job_performance']\n",
    "del test_set['job_performance']\n",
    "\n",
    "print(\"Training Set Shape:\",train_set.shape)\n",
    "print(\"Validation Set Shape:\",validation_set.shape)\n",
    "print(\"Test Set Shape:\",test_set.shape)\n",
    "print(train_targets.head(5))\n",
    "print(validation_targets.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Shape: (16000, 378) \n",
      "  Forcing column 'v71' to numerical data. \n",
      "  Preprocessing: \n",
      "    Numerical: Missing Value Ratio Filter (>0.5) \n",
      "      Starting Numerical Features:  84\n",
      "      Remaining Numerical Features: 36\n",
      "    Numerical: Imputation \n",
      "    Numerical: Normalization \n",
      "    Numerical: Low Variance Filter (>0.01) \n",
      "      Starting Numerical Features:  36\n",
      "      Remaining Numerical Features: 30\n",
      "    Categorical: Missing Value Ratio Filter (>0.5) \n",
      "      Starting Categorical Features:  294\n",
      "      Remaining Categorical Features: 294\n",
      "    Categorical: Imputation \n",
      "    Categorical: Conversion of Ints to Strings \n",
      "    Categorical: One Hot Encoding \n",
      "      Starting Categorical Features: 294\n",
      "      Remaining Categorical Features: 2769\n",
      "    Categorical: Low Variance Filter (>0.01) \n",
      "      Starting Categorical Features:  2769\n",
      "      Remaining Categorical Features: 2769\n",
      "  Recombined Numerical & Categorical Shape:  (16000, 2799)\n",
      "  Dimensionality Reduction:  \n",
      "    Converted Matrix to DataFrame\n",
      "    High Correlation Filter (> 0.9) \n",
      "      Selected Features: 2309\n",
      "Final Shape: (16000, 2309)\n",
      "\n",
      "Starting Shape: (16000, 378) \n",
      "  Forcing column 'v71' to numerical data. \n",
      "  Preprocessing: \n",
      "    Numerical: Missing Value Ratio Filter (>0.5) \n",
      "      Starting Numerical Features:  84\n",
      "      Remaining Numerical Features: 36\n",
      "    Numerical: Imputation \n",
      "    Numerical: Normalization \n",
      "    Numerical: Low Variance Filter (>0.01) \n",
      "      Starting Numerical Features:  36\n",
      "      Remaining Numerical Features: 30\n",
      "    Categorical: Missing Value Ratio Filter (>0.5) \n",
      "      Starting Categorical Features:  294\n",
      "      Remaining Categorical Features: 294\n",
      "    Categorical: Imputation \n",
      "    Categorical: Conversion of Ints to Strings \n",
      "    Categorical: One Hot Encoding \n",
      "      Starting Categorical Features: 294\n",
      "      Remaining Categorical Features: 2769\n",
      "    Categorical: Low Variance Filter (>0.01) \n",
      "      Starting Categorical Features:  2769\n",
      "      Remaining Categorical Features: 2769\n",
      "  Recombined Numerical & Categorical Shape:  (4000, 2799)\n",
      "  Dimensionality Reduction:  \n",
      "    Converted Matrix to DataFrame\n",
      "    High Correlation Filter (> 0.9) \n",
      "      Selected Features: 2309\n",
      "Final Shape: (4000, 2309)\n",
      "\n",
      "Starting Shape: (16000, 378) \n",
      "  Forcing column 'v71' to numerical data. \n",
      "  Preprocessing: \n",
      "    Numerical: Missing Value Ratio Filter (>0.5) \n",
      "      Starting Numerical Features:  84\n",
      "      Remaining Numerical Features: 36\n",
      "    Numerical: Imputation \n",
      "    Numerical: Normalization \n",
      "    Numerical: Low Variance Filter (>0.01) \n",
      "      Starting Numerical Features:  36\n",
      "      Remaining Numerical Features: 30\n",
      "    Categorical: Missing Value Ratio Filter (>0.5) \n",
      "      Starting Categorical Features:  294\n",
      "      Remaining Categorical Features: 294\n",
      "    Categorical: Imputation \n",
      "    Categorical: Conversion of Ints to Strings \n",
      "    Categorical: One Hot Encoding \n",
      "      Starting Categorical Features: 294\n",
      "      Remaining Categorical Features: 2769\n",
      "    Categorical: Low Variance Filter (>0.01) \n",
      "      Starting Categorical Features:  2769\n",
      "      Remaining Categorical Features: 2769\n",
      "  Recombined Numerical & Categorical Shape:  (20000, 2799)\n",
      "  Dimensionality Reduction:  \n",
      "    Converted Matrix to DataFrame\n",
      "    High Correlation Filter (> 0.9) \n",
      "      Selected Features: 2309\n",
      "Final Shape: (20000, 2309)\n"
     ]
    }
   ],
   "source": [
    "import pipeline_functions\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from pipeline_functions import Print, MissingValueRatioFilter, StartTimer, ForceToNumerical, \\\n",
    "ConvertToDataFrame, HighCorrelationFilter, OutputRunTime, ChangeDType\n",
    "\n",
    "X = train_set.copy(deep=True)\n",
    "V = validation_set.copy(deep=True)\n",
    "T = test_set.copy(deep=True)\n",
    "\n",
    "X['v71'] = pd.to_numeric(X['v71'], errors='coerce')\n",
    "V['v71'] = pd.to_numeric(V['v71'], errors='coerce')\n",
    "T['v71'] = pd.to_numeric(T['v71'], errors='coerce')\n",
    "\n",
    "\n",
    "# Numerical transformations\n",
    "numerical_missing_ratio = 0.5\n",
    "variance_threshold = 0.01\n",
    "numerical_colums = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']  \n",
    "numerical_features = list(X.select_dtypes(include=numerical_colums).columns)  \n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('print1', Print(message=\"  Preprocessing:\")),\n",
    "    ('print2', Print(message=\"    Numerical: Missing Value Ratio Filter (>\"+str(numerical_missing_ratio)+\")\")),\n",
    "    ('print3', Print(message=\"      Starting Numerical Features: \",columns=True)),\n",
    "    ('missing_value_ratio_filter', MissingValueRatioFilter(ratio_missing=numerical_missing_ratio)),\n",
    "    ('print4', Print(message=\"      Remaining Numerical Features:\",columns=True)),\n",
    "    ('print5', Print(message=\"    Numerical: Imputation\")),\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('print6', Print(message=\"    Numerical: Normalization\")),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('print7', Print(message=\"    Numerical: Low Variance Filter (>\"+str(variance_threshold)+\")\")),\n",
    "    ('print8', Print(message=\"      Starting Numerical Features: \",columns=True)),\n",
    "    ('variance_threshold', VarianceThreshold(threshold=variance_threshold)),\n",
    "    ('print9', Print(message=\"      Remaining Numerical Features:\",columns=True))\n",
    "    ])\n",
    "\n",
    "# Categorical transformations\n",
    "categorical_missing_ratio = 0.5\n",
    "categorical_variance_threshold = 0.01\n",
    "categorical_features = X.select_dtypes(['object']).columns\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('print0', Print(message=\"    Categorical: Missing Value Ratio Filter (>\"+str(categorical_missing_ratio)+\")\")),\n",
    "    ('print1', Print(message=\"      Starting Categorical Features: \",columns=True)),\n",
    "#     ('missing_value_ratio_filter', MissingValueRatioFilter(ratio_missing=categorical_missing_ratio)),\n",
    "    ('print2', Print(message=\"      Remaining Categorical Features:\",columns=True)),\n",
    "    ('print3', Print(message=\"    Categorical: Imputation\")),\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('print4', Print(message=\"    Categorical: Conversion of Ints to Strings\")),\n",
    "    ('change_dtype', ChangeDType()),\n",
    "    ('print5', Print(message=\"    Categorical: One Hot Encoding\")),\n",
    "    ('print6', Print(message=\"      Starting Categorical Features:\",columns=True)),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ('print7', Print(message=\"      Remaining Categorical Features:\",columns=True)),\n",
    "    ('print8', Print(message=\"    Categorical: Low Variance Filter (>\"+str(categorical_variance_threshold)+\")\")),\n",
    "    ('print9', Print(message=\"      Starting Categorical Features: \",columns=True)),\n",
    "#     ('variance_threshold', VarianceThreshold(threshold=categorical_variance_threshold)),\n",
    "    ('print10', Print(message=\"      Remaining Categorical Features:\",columns=True))\n",
    "    ])\n",
    "\n",
    "# Combine numerical and categorical data back together\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Master pipeline\n",
    "high_correlation_filter_decimal = 0.9\n",
    "master_pipeline = Pipeline([\n",
    "    ('start_timer', StartTimer()),\n",
    "    ('print1', Print(message=\"\\nStarting Shape: \", return_shape=True)),\n",
    "#     ('print2', Print(message=\"  Forcing column 'v71' to numerical data.\")),\n",
    "#     ('force_to_numerical', ForceToNumerical()),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('print3', Print(message=\"  Recombined Numerical & Categorical Shape: \",return_shape=True)),\n",
    "    ('print4', Print(message=\"  Dimensionality Reduction: \")),\n",
    "    ('convert_to_dataframe', ConvertToDataFrame()),\n",
    "    ('print5', Print(message=\"    High Correlation Filter (> \" + str(high_correlation_filter_decimal) + \")\")),\n",
    "    ('high_correlation_filter', HighCorrelationFilter(correlation_decimal=high_correlation_filter_decimal)),\n",
    "    ('print6', Print(message=\"Final Shape:\",return_shape=True)),\n",
    "#     ('output_run_time', OutputRunTime(start_time=master_pipeline.named_steps['start_timer'].start_time))\n",
    "])\n",
    "\n",
    "# Run numerical data only\n",
    "  # X = pd.DataFrame(numerical_transformer.fit_transform(cleaned_train_set[numerical_features]))\n",
    "  # X.head(10)\n",
    "\n",
    "\n",
    "##### Run on train set\n",
    "##### Last runtime = 7,094 seconds\n",
    "train_set_processed = pd.DataFrame(master_pipeline.fit_transform(X))\n",
    "validation_set_processed = pd.DataFrame(master_pipeline.transform(V))\n",
    "test_set_processed = pd.DataFrame(master_pipeline.transform(T))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Pipeline Fit Values to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocessing_pipeline_v1.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(master_pipeline, '2222_preprocessing_params.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pipeline File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Shape: (16000, 378) \n",
      "  Forcing column 'v71' to numerical data. \n",
      "  Preprocessing: \n",
      "    Numerical: Missing Value Ratio Filter (>0.5) \n",
      "      Starting Numerical Features:  84\n",
      "      Remaining Numerical Features: 36\n",
      "    Numerical: Imputation \n",
      "    Numerical: Normalization \n",
      "    Numerical: Low Variance Filter (>0.01) \n",
      "      Starting Numerical Features:  36\n",
      "      Remaining Numerical Features: 31\n",
      "    Categorical: Missing Value Ratio Filter (>0.5) \n",
      "      Starting Categorical Features:  294\n",
      "      Remaining Categorical Features: 294\n",
      "    Categorical: Imputation \n",
      "    Categorical: Conversion of Ints to Strings \n",
      "    Categorical: One Hot Encoding \n",
      "      Starting Categorical Features: 294\n",
      "      Remaining Categorical Features: 2762\n",
      "    Categorical: Low Variance Filter (>0.01) \n",
      "      Starting Categorical Features:  2762\n",
      "      Remaining Categorical Features: 2762\n",
      "  Recombined Numerical & Categorical Shape:  (20000, 2793)\n",
      "  Dimensionality Reduction:  \n",
      "    Converted Matrix to DataFrame\n",
      "    High Correlation Filter (> 0.9) \n",
      "      Selected Features: 8\n",
      "Final Shape: (20000, 8)\n"
     ]
    }
   ],
   "source": [
    "pipeline = joblib.load('master_pipeline.joblib') \n",
    "test_set_processed = pipeline.transform(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Preprocessed Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_processed.to_csv(r'./data/2769_Preprocessed_TrainingSet.csv', index=False)\n",
    "validation_set_processed.to_csv(r'./data/2769_Preprocessed_ValidationSet.csv', index=False)\n",
    "test_set_processed.to_csv(r'./data/2769_Preprocessed_TestSet.csv', index=False)\n",
    "# train_targets.to_csv(r'./data/Preprocessed_TrainingTargets.csv', header=['job_performance'], index=False)\n",
    "# test_targets.to_csv(r'./data/Preprocessed_TestingTargets.csv', header=['job_performance'], index=False)\n",
    "\n",
    "## Filled NAs with mean\n",
    "#1815 (7,094 seconds) was with 0.7 missing ratio filter and .01 variance filter on numerical, no filters on categorical, high correlation filter of 0.9\n",
    "#1616 (4,155 seconds) was with 0.5 missing ratio filter and .01 variance filter on numerical, no filters on categorical, high correlation filter of 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
